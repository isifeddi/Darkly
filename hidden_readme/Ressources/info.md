# EXPLANATION

In the /.hidden route found in /robots.txt.
The idea here is to make a crawler that will read all the readme files in all nested links . In order to find something that can help in finding the flag.

# UTILITY



# HOW TO AVOID ?

Use htaccess to protect the directory
Don't use robots.txt for sensibles process.